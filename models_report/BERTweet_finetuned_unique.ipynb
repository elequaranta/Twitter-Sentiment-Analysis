{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e94b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "from transformers import TextClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fb2b17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11271 entries, 0 to 11270\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    11271 non-null  object\n",
      " 1   label   11271 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 176.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dfo = pd.read_csv('data/obama_cleaned.csv')\n",
    "dfo = dfo.rename(columns={'tweets' : 'text', 'class' : 'label'})\n",
    "dfr = pd.read_csv('data/romney_cleaned.csv')\n",
    "dfr = dfr.rename(columns={'tweets' : 'text', 'class' : 'label'})\n",
    "df = pd.concat([dfo, dfr], ignore_index = True)\n",
    "df.info()\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "697deb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'text' : 'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f1d5181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11271 entries, 0 to 11270\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    11271 non-null  string\n",
      " 1   label   11271 non-null  int64 \n",
      "dtypes: int64(1), string(1)\n",
      "memory usage: 176.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77694489",
   "metadata": {},
   "source": [
    "# Pre-trained model: BERTweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed82996",
   "metadata": {},
   "source": [
    "Fine-tuning using our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19350299",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = df['text']\n",
    "y0 = df['label'].map({1 : 2, 0 : 1, -1 : 0})\n",
    "X, X_test, y, y_test = train_test_split(X0, y0, test_size = 0.2, random_state = 27)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size = 0.25, random_state = 27)\n",
    "\n",
    "\n",
    "traindf = pd.concat([X_train,y_train], axis = 1)\n",
    "\n",
    "evaldf = pd.concat([X_eval,y_eval], axis = 1)\n",
    "\n",
    "testdf = pd.concat([X_test,y_test], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "254787af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Dataset.from_pandas(traindf, split = 'train')\n",
    "val = Dataset.from_pandas(evaldf, split = 'eval')\n",
    "test = Dataset.from_pandas(testdf, split = 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f56bb2b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e20bc275544d9495929cbd30c6e101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6762 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6916418de544e386b9528dcf06b9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2254 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86505bb366040429abf77e7bd5184d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2255 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "    \n",
    "\n",
    "tokenized_train = train.map(tokenize_function, batched=True)\n",
    "tokenized_eval = val.map(tokenize_function, batched=True)\n",
    "tokenized_test = test.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5885312f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2538' max='2538' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2538/2538 28:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.858800</td>\n",
       "      <td>0.775103</td>\n",
       "      <td>0.660603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.597200</td>\n",
       "      <td>0.893185</td>\n",
       "      <td>0.696983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>1.039635</td>\n",
       "      <td>0.691216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2538, training_loss=0.5951146617285185, metrics={'train_runtime': 1718.2219, 'train_samples_per_second': 11.806, 'train_steps_per_second': 1.477, 'total_flos': 1334379698007552.0, 'train_loss': 0.5951146617285185, 'epoch': 3.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\", num_labels=3)\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"checkpoints/test_trainer_unique\", evaluation_strategy=\"epoch\", num_train_epochs=3)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae38c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('models/model_unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b588c",
   "metadata": {},
   "source": [
    "# Load from checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a55397",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"checkpoints/test_trainer_unique/checkpoint-1000\", num_labels=3)\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer_unique\", evaluation_strategy=\"epoch\", num_train_epochs=5)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b12e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('models/model_unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9522d5",
   "metadata": {},
   "source": [
    "# Load finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6400df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('models/model_unique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5af7dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d66d5c02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos = list()\n",
    "neg = list()\n",
    "neu = list()\n",
    "pred = pd.DataFrame()\n",
    "for t in testdf['text']:\n",
    "    prediction = pipe(t, top_k=None)\n",
    "    for l in prediction:\n",
    "        if l['label'] == 'POS':\n",
    "            pos.append(l['score'])\n",
    "        elif l['label'] == 'NEG':\n",
    "            neg.append(l['score'])\n",
    "        else: \n",
    "            neu.append(l['score'])\n",
    "            \n",
    "pred['pos'] = pos\n",
    "pred['neg'] = neg\n",
    "pred['neu'] = neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b4a4e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred['class'] = list(testdf['label'].map({0 : -1, 1 : 0, 2 : 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc575a6",
   "metadata": {},
   "source": [
    "# Predict label using maximum probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6dfd0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_label(df):\n",
    "    preds = list()\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['pos'] >= row['neu'] and row['pos'] >= row['neg']:\n",
    "            preds.append(1)\n",
    "        elif row['neg'] >= row['neu'] and row['neg'] > row['pos']:\n",
    "            preds.append(-1)\n",
    "        elif row['neu'] > row['pos'] and row['neu'] > row['neg']:\n",
    "            preds.append(0)\n",
    "    df['pred'] = preds\n",
    "    acc = accuracy_score(df['class'], df['pred'])\n",
    "    prec = precision_score(df['class'], df['pred'], average = None, zero_division = np.nan)\n",
    "    rec = recall_score(df['class'], df['pred'], average = None)\n",
    "    f1 = f1_score(df['class'], df['pred'], average = None)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Recall:\", rec)\n",
    "    print(\"F1:\", f1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6722c123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7024390243902439\n",
      "Precision: [0.75       0.62426036 0.70777989]\n",
      "Recall: [0.78664008 0.58367911 0.70510397]\n",
      "F1: [0.76788321 0.60328806 0.70643939]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = pred_label(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63ca29f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
