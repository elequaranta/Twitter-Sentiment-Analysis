{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e94b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoTokenizer, TextClassificationPipeline\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fb2b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo = pd.read_csv('data/obama_cleaned.csv')\n",
    "dfo = dfo.rename(columns={'tweets' : 'text', 'class' : 'label'})\n",
    "\n",
    "dfr = pd.read_csv('data/romney_cleaned.csv')\n",
    "dfr = dfr.rename(columns={'tweets' : 'text', 'class' : 'label'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77694489",
   "metadata": {},
   "source": [
    "# Pre-trained model: BERTweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed82996",
   "metadata": {},
   "source": [
    "Fine-tuning using our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19350299",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xo = dfo['text']\n",
    "yo = dfo['label'].map({1 : 2, 0 : 1, -1 : 0})\n",
    "Xo_train, Xo_eval, yo_train, yo_eval = train_test_split(Xo, yo, test_size = 0.25, random_state = 21)\n",
    "\n",
    "Xr = dfr['text']\n",
    "yr = dfr['label'].map({1 : 2, 0 : 1, -1 : 0})\n",
    "Xr_train, Xr_eval, yr_train, yr_eval = train_test_split(Xr, yr, test_size = 0.25, random_state = 21)\n",
    "\n",
    "\n",
    "traindf_o = pd.concat([Xo_train,yo_train], axis = 1)\n",
    "evaldf_o = pd.concat([Xo_eval,yo_eval], axis = 1)\n",
    "\n",
    "traindf_r = pd.concat([Xr_train,yr_train], axis = 1)\n",
    "evaldf_r = pd.concat([Xr_eval,yr_eval], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254787af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_o = Dataset.from_pandas(traindf_o, split = 'train')\n",
    "eval_o = Dataset.from_pandas(evaldf_o, split = 'eval')\n",
    "\n",
    "train_r = Dataset.from_pandas(traindf_r, split = 'train')\n",
    "eval_r = Dataset.from_pandas(evaldf_r, split = 'eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56bb2b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab256db26b124bf4a7bdfe84602982eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4218 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00e238ea88a4d8cbff5a771b2c5059c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1406 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acb6492fb3644bb9693c7beac554520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4235 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712a49f7dd8f4edfa65fffcde2678e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1406 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "    \n",
    "tokenized_train_o = train_o.map(tokenize_function, batched=True)\n",
    "tokenized_eval_o = eval_o.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_train_r = train_r.map(tokenize_function, batched=True)\n",
    "tokenized_eval_r = eval_o.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5885312f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1056' max='1056' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1056/1056 08:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.792200</td>\n",
       "      <td>0.695829</td>\n",
       "      <td>0.700569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.498800</td>\n",
       "      <td>0.794279</td>\n",
       "      <td>0.712660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1056, training_loss=0.632978663300023, metrics={'train_runtime': 486.7197, 'train_samples_per_second': 17.332, 'train_steps_per_second': 2.17, 'total_flos': 554906197988352.0, 'train_loss': 0.632978663300023, 'epoch': 2.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_o = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\", num_labels=3)\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args_o = TrainingArguments(output_dir=\"checkpoints/test_trainer_o\", evaluation_strategy=\"epoch\", num_train_epochs=2)\n",
    "\n",
    "trainer_o = Trainer(\n",
    "    model=model_o,\n",
    "    args=training_args_o,\n",
    "    train_dataset=tokenized_train_o,\n",
    "    eval_dataset=tokenized_eval_o,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_o.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae38c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_o.save_model('models/obama_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c754bfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1590' max='1590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1590/1590 12:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>0.934538</td>\n",
       "      <td>0.611664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.571400</td>\n",
       "      <td>1.021661</td>\n",
       "      <td>0.585349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.372800</td>\n",
       "      <td>1.470590</td>\n",
       "      <td>0.580370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1590, training_loss=0.5800815174414676, metrics={'train_runtime': 749.6024, 'train_samples_per_second': 16.949, 'train_steps_per_second': 2.121, 'total_flos': 835713993058560.0, 'train_loss': 0.5800815174414676, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_r = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\", num_labels=3)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args_r = TrainingArguments(output_dir=\"checkpoints/test_trainer_r\", evaluation_strategy=\"epoch\", num_train_epochs=3)\n",
    "\n",
    "trainer_r = Trainer(\n",
    "    model=model_r,\n",
    "    args=training_args_r,\n",
    "    train_dataset=tokenized_train_r,\n",
    "    eval_dataset=tokenized_eval_r,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_r.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43cbb9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_r.save_model('models/romney_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b588c",
   "metadata": {},
   "source": [
    "# Load from checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8394d047",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_o = AutoModelForSequenceClassification.from_pretrained(\"checkpoints/test_trainer_o\", num_labels=3)\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args_o = TrainingArguments(output_dir=\"test_trainer_o\", evaluation_strategy=\"epoch\", num_train_epochs=2)\n",
    "\n",
    "trainer_o = Trainer(\n",
    "    model=model_o,\n",
    "    args=training_args_o,\n",
    "    train_dataset=tokenized_train_o,\n",
    "    eval_dataset=tokenized_test_o,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_o.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9940c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r = AutoModelForSequenceClassification.from_pretrained(\"checkpoints/test_trainer_r\", num_labels=3)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args_r = TrainingArguments(output_dir=\"checkpoints/test_trainer_r\", evaluation_strategy=\"epoch\", num_train_epochs=3)\n",
    "\n",
    "trainer_r = Trainer(\n",
    "    model=model_r,\n",
    "    args=training_args_r,\n",
    "    train_dataset=tokenized_train_r,\n",
    "    eval_dataset=tokenized_eval_r,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_r.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
