{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "from transformers import TextClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo = pd.read_csv('data/obama_cleaned.csv', dtype={'tweets': 'string', 'class': 'int8'})\n",
    "dfo = dfo.rename(columns={'tweets' : 'text', 'class' : 'label'})\n",
    "dfr = pd.read_csv('data/romney_cleaned.csv', dtype={'tweets': 'string', 'class': 'int8'})\n",
    "dfr = dfr.rename(columns={'tweets' : 'text', 'class' : 'label'})\n",
    "df = pd.concat([dfo, dfr], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2792f469fef8471485924f0f5bf9e596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570b6e18681f4fa6b67cb5fd74230c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce92b6dd83e44d1a463f5dd9cbcda82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8be27f8d1d41b0a035120225827310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707a668bdc144450baac090e4b66810a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\", num_labels=3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = list()\n",
    "neg = list()\n",
    "neu = list()\n",
    "pred = pd.DataFrame()\n",
    "for t in df['text']:\n",
    "    prediction = pipe(t)\n",
    "    neg.append(prediction[0][0]['score'])\n",
    "    neu.append(prediction[0][1]['score'])\n",
    "    pos.append(prediction[0][2]['score'])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred['pos'] = pos\n",
    "pred['neg'] = neg\n",
    "pred['neu'] = neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred['class'] = list(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_label(df):\n",
    "    preds = list()\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['pos'] >= row['neu'] and row['pos'] >= row['neg']:\n",
    "            preds.append(1)\n",
    "        elif row['neg'] >= row['neu'] and row['neg'] > row['pos']:\n",
    "            preds.append(-1)\n",
    "        elif row['neu'] > row['pos'] and row['neu'] > row['neg']:\n",
    "            preds.append(0)\n",
    "    df['pred'] = preds\n",
    "    acc = accuracy_score(df['class'], df['pred'])\n",
    "    prec = precision_score(df['class'], df['pred'], average = None, zero_division = np.nan)\n",
    "    rec = recall_score(df['class'], df['pred'], average = None)\n",
    "    f1 = f1_score(df['class'], df['pred'], average = None)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Recall:\", rec)\n",
    "    print(\"F1:\", f1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5918729482743323\n",
      "Precision: [0.68115661 0.47357383 0.66888889]\n",
      "Recall: [0.72222222 0.61744599 0.32788671]\n",
      "F1: [0.70108858 0.53602374 0.44005848]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = pred_label(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
